{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Transformations used to convert original dataset to match SOPHY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import geolabel\n",
    "import sophysql\n",
    "import sophytaxa\n",
    "import cartopy.crs as ccrs\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"test.db\")\n",
    "with open('schema.sql', 'r') as sql_file:\n",
    "    con.executescript(sql_file.read())\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1) Palmer LTER dataset\n",
    "- Link to source and info"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lter1 = pd.read_csv(\"../data/in/datasets/unmodified/AntarcticaLTERcompiledData_Cruise_forEDI.csv\")\n",
    "lter2 = pd.read_csv(\"../data/in/datasets/unmodified/AntarcticaLTERcompiledData_Station_forEDI.csv\")\n",
    "\n",
    "lter_sql: dict = {\"DatetimeGMT\": \"timestamp\", \"Latitude\": \"latitude\", \"Longitude\": \"longitude\",\n",
    "                  \"Depth\": \"depth\", \"Temperature\": \"temperature\", \"Salinity\": \"salinity\", \"Density\": \"density\",\n",
    "                  \"Chlorophyll\": \"chl_a\", \"Fluorescence\": \"fluorescence\", \"Phaeopigment\": \"phaeopigments\",\n",
    "                  \"PrimaryProduction\": \"primary_prod\", \"studyName\": \"cruise\", \"PAR\": \"par\",\n",
    "                  \"Prasinophytes\": \"prasinophytes\", \"Cryptophytes\": \"cryptophytes\",\n",
    "                  \"MixedFlagellates\": \"mixed_flagellates\", \"Diatoms\": \"diatoms\", \"Haptophytes\": \"haptophytes\",\n",
    "                  \"NO3\": \"nitrate\", \"NO2\": \"nitrite\", \"DIC1\": \"diss_inorg_carbon\", \"DOC\": \"diss_org_carbon\",\n",
    "                  \"POC\": \"part_org_carbon\", \"SiO4\": \"silicate\", \"N\": \"tot_nitrogen\",\n",
    "                  \"PO4\": \"phosphate\", \"Notes1\": \"notes\"}\n",
    "\n",
    "lter1 = lter1[lter_sql.keys()].rename(columns=lter_sql)\n",
    "lter2 = lter2[lter_sql.keys()].rename(columns=lter_sql)\n",
    "lter = pd.concat([lter1, lter2])\n",
    "lter = lter.dropna(subset=['timestamp', 'longitude', 'latitude'])\n",
    "# TODO: warning if any values were dropped\n",
    "lter = lter[lter['longitude'].between(-180, 180)]\n",
    "lter = lter[lter['latitude'] <= -30]\n",
    "# Group chemtax into three main categories\n",
    "lter['percent_phaeo'] = lter['haptophytes']\n",
    "lter['percent_diatom'] = lter['diatoms']\n",
    "lter['percent_prasinophytes'] = lter['prasinophytes']\n",
    "lter['percent_other'] = lter['mixed_flagellates'] + lter['cryptophytes']\n",
    "\n",
    "data_gdf = GeoDataFrame(lter, geometry=gpd.points_from_xy(lter['longitude'], lter['latitude']), crs='EPSG:4326')\n",
    "data_gdf = data_gdf.to_crs(crs=ccrs.SouthPolarStereo())\n",
    "zones_gdf = gpd.read_file(geolabel.zones_shapefile).to_crs(ccrs.SouthPolarStereo())\n",
    "# Spatially join data points with zones (polygons) to get labelled data\n",
    "lter = DataFrame(data_gdf.sjoin(zones_gdf, how='left').drop(columns=['geometry', 'index_right']))\n",
    "sectors_series: pd.Series = pd.cut(lter['longitude'], bins=[-180, -130, -60, 20, 90, 160, 180],\n",
    "                                    labels=['Ross', 'BA', 'Weddell', 'Indian', 'WPO', 'Ross'], ordered=False)\n",
    "lter = lter.assign(sector=sectors_series)\n",
    "\n",
    "extra = lter.columns.difference(sophysql.get_table_cols(\"sample\"))\n",
    "lter[\"extra_json\"] = lter[extra].agg(lambda r: r[r.notna()].to_json(), axis=1)\n",
    "lter = lter.drop(extra, axis=1)\n",
    "lter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lter.to_sql(name='sample', con=con, if_exists='append', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2) Joy-Warren 2019 dataset\n",
    "- Link to source and info"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"Writes Joy-Warren 2019 dataset to database\"\"\"\n",
    "joyw: DataFrame = pd.read_csv('../data/in/datasets/modified/joy_warren.csv', encoding='utf-8')\n",
    "# group by depth and station: station1([1.7, 1.8, 2.1][9.7. 9.8, 10.2]...), station2...\n",
    "joyw = joyw.groupby([joyw[\"depth\"].pct_change().abs().gt(0.15).cumsum(), \"station\"]).mean(numeric_only=True)\n",
    "joyw = joyw.reset_index(level=0, drop=True).reset_index(level=0).sort_values(by='depth')\n",
    "joyw.sort_values(by=['station', 'depth'])\n",
    "# --------------------------------------------------\n",
    "jwchemtax = pd.read_csv('../data/in/datasets/modified/joy_warren_chemtax.csv')\n",
    "jwchemtax = jwchemtax.dropna().sort_values(by='depth')\n",
    "# --------------------------------------------------\n",
    "# Join main sample data with chemtax by matching station and depth\n",
    "joyw: DataFrame = pd.merge_asof(jwchemtax, joyw, by='station', on='depth', direction='nearest',\n",
    "                                  tolerance=2).sort_values(by='station')\n",
    "\n",
    "joyw['timestamp'] = pd.to_datetime(joyw['date'], format='%Y%m%d', errors='coerce').dropna().drop(\n",
    "    columns=['date', 'time'])\n",
    "joyw['source_name'] = 'joyw'\n",
    "joyw['percent_phaeo'] = joyw['haptophytes']\n",
    "joyw['percent_diatom'] = joyw['diatoms']\n",
    "joyw['percent_other'] = joyw['chlorophytes'] + joyw['mixed_flagellates'] + joyw['cryptophytes']\n",
    "# ----------------------------------------------------\n",
    "# Set id field for sample data so foreign keys for microscopy can be matched\n",
    "joyw = joyw.reset_index(drop=True)\n",
    "max_id: int = pd.read_sql(\"select max(id) from sample\", con=con)['max(id)'][0] + 1\n",
    "joyw['id'] = np.arange(max_id, max_id + len(joyw))\n",
    "jwmkey = pd.concat([joyw['id'], joyw['station'], joyw['depth']], axis=1).sort_values(by='depth')\n",
    "# Group extra columns into JSON\n",
    "extra = joyw.columns.difference(sophysql.get_table_cols(\"sample\"))\n",
    "joyw[\"extra_json\"] = joyw[extra].agg(lambda r: r[r.notna()].to_json(), axis=1)\n",
    "joyw = joyw.drop(columns=extra, axis=1)\n",
    "\n",
    "microscopy = pd.read_csv('../data/in/datasets/modified/joy_warren_microscopy.csv', encoding='utf-8').dropna()\n",
    "replace: tuple = ('centric', 'pennate', 'unknown diatom', 'dinoflagellate', 'ciliate', 'silicoflagellate')\n",
    "# are_taxa = rows that have species name we can get taxonomy for (ex: Phaeocystis)\n",
    "are_taxa = ~microscopy['taxa'].isin(replace)\n",
    "taxa: DataFrame = pd.read_csv(\"../data/in/worms/joy_warren_worms.csv\", encoding='utf-8').rename(sophytaxa.worms_sql)\n",
    "taxa.index = microscopy[are_taxa].index\n",
    "# ----------------------------------\n",
    "microscopy['aphia_id'] = taxa['AphiaID']\n",
    "microscopy = microscopy.sort_values(by='depth')\n",
    "# Join microscopy data with matching id in sample table (by depth and station)\n",
    "microscopy = pd.merge_asof(microscopy, jwmkey, by='station', on='depth', direction='nearest', tolerance=1)\n",
    "microscopy = microscopy.rename({'id': 'sample_id', 'taxa': 'name', 'group': 'groups'},\n",
    "                               axis=\"columns\")\n",
    "# Remove extra columns\n",
    "microscopy = microscopy[microscopy.columns.intersection(sophysql.get_table_cols(\"microscopy\"))]\n",
    "\n",
    "data_gdf = GeoDataFrame(joyw, geometry=gpd.points_from_xy(joyw['longitude'], joyw['latitude']), crs='EPSG:4326')\n",
    "data_gdf = data_gdf.to_crs(crs=ccrs.SouthPolarStereo())\n",
    "zones_gdf = gpd.read_file(geolabel.zones_shapefile).to_crs(ccrs.SouthPolarStereo())\n",
    "# Spatially join data points with zones (polygons) to get labels for zones and sectors\n",
    "joyw = DataFrame(data_gdf.sjoin(zones_gdf, how='left').drop(columns=['geometry', 'index_right'])).drop_duplicates(subset=['id'])\n",
    "sectors_series: pd.Series = pd.cut(joyw['longitude'], bins=[-180, -130, -60, 20, 90, 160, 180],\n",
    "                                    labels=['Ross', 'BA', 'Weddell', 'Indian', 'WPO', 'Ross'], ordered=False)\n",
    "joyw = joyw.assign(sector=sectors_series)\n",
    "joyw"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "joyw.to_sql(name='sample', con=con, if_exists='append', index=False)\n",
    "microscopy.to_sql(name='microscopy', con=con, if_exists='append', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3) Phytobase\n",
    "- Link to source and info"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "phybase: DataFrame = pd.read_csv('../data/in/datasets/mod/phytobase.csv')\n",
    "phybase['timestamp'] = pd.to_datetime(phybase['timestamp'], errors='coerce')\n",
    "# get full taxonomy of microscopy data as dataframe\n",
    "taxa: DataFrame = pd.read_csv('../data/in/worms/phytobase_worms.csv')[['original', 'AphiaID']]\n",
    "# join on sample and taxonomy (by aphia_id), only keep cols in the occurrence table (filter out order, genus, etc)\n",
    "phybase = pd.merge(phybase, taxa, left_on='scientificname', right_on='original')\n",
    "phybase = phybase.rename(columns=sophytaxa.worms_sql).filter(sophysql.get_table_cols(\"occurrence\"))\n",
    "\n",
    "data_gdf = GeoDataFrame(phybase, geometry=gpd.points_from_xy(phybase['longitude'], phybase['latitude']), crs='EPSG:4326')\n",
    "data_gdf = data_gdf.to_crs(crs=ccrs.SouthPolarStereo())\n",
    "zones_gdf = gpd.read_file(geolabel.zones_shapefile).to_crs(ccrs.SouthPolarStereo())\n",
    "# Spatially join data points with zones (polygons) to get labelled data\n",
    "phybase = DataFrame(data_gdf.sjoin(zones_gdf, how='left').drop(columns=['geometry', 'index_right']))\n",
    "sectors_series: pd.Series = pd.cut(phybase['longitude'], bins=[-180, -130, -60, 20, 90, 160, 180],\n",
    "                                    labels=['Ross', 'BA', 'Weddell', 'Indian', 'WPO', 'Ross'], ordered=False)\n",
    "phybase = phybase.assign(sector=sectors_series)\n",
    "phybase"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "phybase.to_sql(name='occurrence', con=con, if_exists='append', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4) Alderkamp dataset\n",
    "- Link to source and info"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.read_sql(\"select * from sample;\", con=con)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "5) Garibotti dataset\n",
    "- Link to source and info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:16:53) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b5a161a6368859e3eadb98cca106433d079d50eb5df0ef7500750a84ba1cc1aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}